# Offline AI Agent Configuration

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
DEFAULT_MODEL=codellama

# Logging
LOG_LEVEL=info

# Development
DEBUG=false
RELOAD=true

# File Operations
MAX_FILE_SIZE=10485760  # 10MB
SUPPORTED_EXTENSIONS=.py,.js,.ts,.jsx,.tsx,.java,.cpp,.c,.h,.hpp,.cs,.php,.rb,.go,.rs,.swift,.kt,.scala,.r,.m,.pl,.sh,.bash,.zsh,.fish,.ps1,.bat,.cmd,.html,.css,.scss,.sass,.less,.xml,.json,.yaml,.yml,.toml,.ini,.cfg,.conf,.env,.md,.txt,.sql,.dockerfile,.dockerignore,.gitignore

# AI Model Settings
MAX_TOKENS=2000
TEMPERATURE=0.7
TOP_P=0.9
